### 대규모 데이터의 어려움
- 메모리 내에서 검색할 수 없게 되면 디스크에 있는 데이터를 검색할 필요가 있다.
- 디스크는 느리므로 I/O에 시간이 오래 걸린다.
- 메모리와 디스크는 전송속도에서 100배 이상 차이가 난다. (메모리가 디스크보다 100배이상 빠름)

### CPU 부하 규모조정 , I/O 부하의 규모조정
- CPU 부하 규모조정
    - CPU 부하의 규모조정은 데이터를 분산해서 갖고 있는 것이 아니므로 동일한 호스트가 동일하게 작업을 처리하기만 하면 분산가능하다.
    - 같은 구성의 서버를 늘리고 로드밸런서로 분산시킨다.
- I/O 부하의 규모조정
    - DB를 늘리게 되면 하나의 DB의 데이터를 어떻게 동기화시킬 것인지 문제가 발생한다.
    - DB에서 디스크를 많이 사용하는 상황이라면 속도차 문제가 생기므로 이 문제도 생각해야한다.

### 대규모 데이터를 다루기 위한 요령
- 프로그램 작성할 때의 요령
    - 어떻게 하면 메모리에서 처리를 마칠 수 있을까? 디스크 탐색 횟수를 최소화해야한다.
    - 데이터 증가에 강한 알고리즘 사용 -> 알고리즘의 기초적인 부분을 활용해야한다.
    - 데이터 압축이나 검색기술과 같은 테크닉을 활용한다.
- 프로그램 개발의 한층 아래 기초
    - OS 캐시
    - 분산을 고려하여 RDBMS 운용
    - 대규모 환경에서 알고리즘과 데이터 구조를 사용하는 것

### 가상 메모리 구조
- 1. 메모리 2. OS 3. 애플리케이션 프로세스
- 메모리에는 32비트 주소가 붙어있다. 프로세스에서 메모리를 필요하게 되면 메모리에서 직접 가져오는 것이 아니라 OS가 메모리에서 비어 있는 곳을 찾고 비어있는 메모리를 반환한다.
- 디스크에 경우에도 메모리를 확보할 때 OS가 모아서 4KB 정도 블록으로 확보해서 프로세스에 넘긴다. 여기서 1개의 블록을 페이지라고한다. 
- 페이지 -> 가상메모리의 최소단위

### Linux의 페이지 캐시 원리
- 프로세스가 디스크로부터 데이터를 읽어내는 과정
    1. OS는 디스크로부터 4KB 크기의 블록을 읽어낸다. 읽어낸 것은 한번 메모리상에 위치시킨다.(프로세스는 디스크에 직접 접근 불가) -> 블록을 읽고 메모리에 한번 쓴다.
    2. OS는 그 메모리 주소를 프로세스에 알려준다. 이를 통해 프로세스는 해당 메모리에 접근하게 된다.
- 프로세스가 디스크에 접근하려할 때 남겨두었던 페이지를 사용할 수 있으므로 다시 디스크를 읽으러 갈 필요가 없다. -> 페이지 캐시 , 커널이 한 번 할당한 메모리는 해제하지 않고 남겨둔다.

### 캐시는 계속 남아있기만 하는 걸까? LRU (Least Recently Used)
- 캐시는 가장 오래된 것을 파기하고 새로운 것을 남겨놓는 형태로 되어있다. 따라서 과거에 읽은 부분이 파기되어 간다.

### 메모리를 늘려서 I/O 부하 줄이기
- 리눅스에서 sar -f 명령어로 iowait 을 보면 프로세스가 작업을 수행할 때 I/O에서 대기하는 지 확인할 수 있다.
- %가 높다면 ex) 15, 16 -> 항상 I/O에서 대기하는 것으로 메모리를 늘린다면 이 부분이 줄어드는 것을 볼 수 있다.
- 메모리를 늘리면 데이터베이스상의 파일을 대부분 캐시로 올릴 수 있게 할 수 있다.

### 서버증량은 언제하는게 좋을까? -> 전부 캐싱할 수 없는 경우 (데이터 규모 < 물리메모리 -> 전부 캐싱가능)
- API 서버와 같은 서버의 경우 CPU 부하를 낮추고 분산시키기 위해서
- DB 서버와 같은 경우 부하을 낮추고 캐시용량을 늘리고자 할 때
- DB서버는 많다고 좋은 것이 아니다.. -> 단순히 복사해서 늘리는 경우 캐시 용량이 부족해서 서버를 늘렸는데 부족한 부분까지 동일하게 늘려가게 된다. 캐시 용량 부족 -> 디스크 접근 -> 속도 저하

### 데이터가 많은 서비스의 경우 DB 서버를 재부팅하면?
- 데이터가 매무 많은 서비스에서 유지보수등의 이유로 서버를 재부팅하면 메모리에 캐싱되어 있던 페이지 캐시는 모두 초기화된다. 요청이 많은 DB서버를 캐시가 구축되지 않은 상태로 실제로 가동시키면 모든 DB 엑세스는 디스크 I/O를 발생시키게 되고 대규모의 환경에서는 이를 원인으로 DB가 lock에 걸려 서비스가 불능상태로 되어버린다. 
- 이를 해결하기 위해서 필요한 데이터 전체를 한 번 읽어들인 후에 프로덕션환경으로 되돌리는 방법을 사용할 수 있다.

### 엑세스 패턴에 따른 국소성 분산
- 파티셔닝
    - 파티셔닝이란 한 대였던 DB 서버를 여러 대의 서버로 분할하는 방법이다. 
    - 같이 엑세스하는 경우가 많은 테이블끼리 묶어서 파티셔닝을 한다.
    - 테이블 단위로 파티셔닝을 했다면 애플리케이션에서 요청에 따라 서버를 달리 보내도록 변경할 필요가 있다.

### 페이지 캐시를 고려한 운용의 기본 규칙
- OS 기동 직후에 서버를 투입하지 않는다.
    - 갑자기 배치하면 캐시가 없으므로 오직 디스크 엑세스만 발생하게 되고 대규모 서버일 경우 서버가 내려갈 수도 있다. 따라서 OS를 시작해서 자주 사용하는 DB파일을 한 번 cat 해준다.
- 성능 검사, 부하테스트도 캐시가 최적화된 후 테스트할 필요가 있다.